{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.models.classification_rnn import ClassificationRNN, DEVICE\n",
    "from src.utils.seed import set_seed\n",
    "from src.utils.config import flatten_config\n",
    "from src.datasets.window_maker import make_past_future_windows, load_parquet_files\n",
    "\n",
    "seed = 42\n",
    "test_size = 0.3\n",
    "\n",
    "PARQUET_FILE_FINAL = os.path.join(\"data\", \"aisdk\", \"processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf80ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input dataset...\n",
      "   → Loaded 191,668 rows.\n",
      "Total trajectory segments: 359\n",
      "\n",
      "   → Processed 50/359 segments (+2 windows, cluster 8)\n",
      "   → Processed 100/359 segments (+440 windows, cluster 5)\n",
      "   → Processed 150/359 segments (+1041 windows, cluster 1)\n",
      "   → Processed 200/359 segments (+171 windows, cluster 5)\n",
      "   → Processed 250/359 segments (+547 windows, cluster 1)\n",
      "   → Processed 300/359 segments (+420 windows, cluster 1)\n",
      "   → Processed 350/359 segments (+10 windows, cluster 0)\n",
      "\n",
      "DONE!\n",
      "   → Processed segments: 359\n",
      "   → Total windows generated: 171,461\n",
      "   → Output stored under: data/aisdk/processed/windows_30_30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_past_future_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175799a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, C = load_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aed9cc",
   "metadata": {},
   "source": [
    "### 1.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89a585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the Classification rnn\n",
    "\n",
    "num_epochs = 100\n",
    "weight_decay = 1e-5\n",
    "num_classes = 20 # number of groups from hdbscan\n",
    "hidden_size = 64\n",
    "num_layers = 8\n",
    "batch_size = 128\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e61685",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5149e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch trajectories\n",
    "df = pd.read_parquet('../../data/aisdk/processed/aisdk_2025')\n",
    "\n",
    "# Convert Timestamp to datetime if it's not already\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# Group trajectories\n",
    "trajectories = []\n",
    "    \n",
    "for traj_id in df['Trajectory'].unique():\n",
    "    traj_data = df[df['Trajectory'] == traj_id].sort_values('Timestamp')\n",
    "    features = traj_data[['UTM_x', 'UTM_y', 'SOG', 'v_east', 'v_north']].values\n",
    "    trajectories.append(features)\n",
    "\n",
    "# Split into train / test\n",
    "train, val = train_test_split(trajectories, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Normalize\n",
    "train_stacked = np.vstack(train)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_stacked) \n",
    "\n",
    "train_s = [scaler.transform(traj) for traj in train]\n",
    "val_s = [scaler.transform(traj) for traj in val]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
